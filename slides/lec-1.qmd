---
title: Overview of ML Systems
subtitle: Lecture 1
author: Jan Kirenz
format:
  revealjs:
    theme: default
    transition: fade
    slide-number: true
    chalkboard:
      buttons: false
    preview-links: auto
    logo: images/logo.png
    css: slides.scss
    footer: MLOps | Jan Kirenz
    incremental: true 
#jupyter: python3
---


## Machine Learning

![](images/lec-1/fig-1-2-patterns.png)


## When to use Machine Learning

- The system has the capacity to learn  

- There are patterns to learn, and they are complex  

- Data is available, or it’s possible to collect data

- It's a predicitve problem

- Unseen data shares patterns with the training data

## Machine Learning characteristics

Machine learning is an approach to (1) learn (2) complex patterns from (3) existing data and use these patterns to make (4) predictions on (5) unseen data.


## Additional characteristics

- It's repetitive  

- The cost of wrong predictions is cheap  

- It's at scale  

- The patterns are constantly changing  

- It's not unethical

- It's cost effective (in the long run)


## Typical Machine Learning Use Cases

- Recommender system   

- Machine translation 

- Computer vision

- Chat bots

## ML Use Cases: Booking.com

{{< video https://www.youtube.com/embed/DEjyUkbVVHA width="1920" height="1080" >}}


[150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com](https://booking.ai/150-successful-machine-learning-models-6-lessons-learned-at-booking-com-681e09107bec)


## Enterprise Machine Learning Use Cases

- Fraud detection  

- Price optimization

- Customer acquisition

- Churn prediction 

- Customer service support

- Brand monitoring (sentiment analysis)


## State of AI

[State of AI in 2022 by McKinsey & Company](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2022-and-a-half-decade-in-review#review)


# Understanding Machine Learning Systems {background-color="#0ca37f"}

# 1) ML in Research vs in Production


## Differences between ML in Research and Production

|                        | Research                                                 | Production                                         |
| ---------------------- | -------------------------------------------------------- | -------------------------------------------------- |
| Requirements           | State-of-the-art model performance on benchmark datasets | Different stakeholders have different requirements |
| Computational priority | Fast training, high throughput                           | Fast inference, low latency                        |
| Data                   | Static                                                  | Constantly shifting                                |
| Fairness               | Often not a focus                                        | Must be considered                                 |
| Interpretability       | Often not a focus                                        | Must be considered                                 |


## Different Stakeholders and requirements

- Consider a mobile app that recommends restaurants to users. 
- The app makes money by charging restaurants a 10% service fee on each order. 
- This means that expensive orders give the app more money than cheap orders.


## ML engineers

Want a model that recommends restaurants that users will most likely order
from, and they believe they can do so by using a more complex model with more
data.

## Sales team

Wants a model that recommends the more expensive restaurants since these
restaurants bring in more service fees.

## Product team

Notices that every increase in latency leads to a drop in orders through the
service, so they want a model that can return the recommended restaurants in
less than 100 milliseconds.


## ML platform team

As the traffic grows, this team has been woken up in the middle of the night
because of problems with scaling their existing system, so they want to hold off
on model updates to prioritize improving the ML platform.


## Manager

Wants to maximize the margin, and one way to achieve this might be to let go of
the ML team.

## Different Model Objectives

- Model A: Recommending the restaurants that users are most likely to click on

- Model B: Recommending the restaurants that will bring in the most money for the app

- Which model should be deployed to the users?

- Must-have vs nice-to-have requirements 

## Kaggle vs ML in Production

- Incentivizing the creation of more accurate models at the expense of other qualities
valued by practitioners such as compactness, fairness, and energy efficiency

- Ensemble vs compact model

- Netflix price

## Computational priorities

- Research usually prioritizes fast training

- Production usually prioritizes fast inference

- Research prioritizes high throughput ^[how many
queries are processed within a specific period of time] 

- Production prioritizes low latency ^[the time it takes from receiving a query to returning the result]

## Latency

- It’s a common practice to use high percentiles to specify the performance require‐
ments for your system

- For example, a product manager might specify that the 90th percentile or 99.9th percentile latency of a system must be below a certain number

## Data in research versus data in production 


![](images/lec-1/fig-1-5-sleep.png)


- Source: Andrej Karpathy, “Building the Software 2.0 Stack,” Spark+AI Summit 2018, video, 17:54,
https://oreil.ly/Z21Oz.


## Fairness

- Loan application might be rejected due to biases in the model 
- Resume might be ranked lower because the ranking system picks on the spelling of names
- Mortgage might get a higher interest rate because it relies partially on biased credit scores
- Predictive policing algorithms
- Personality tests administered by potential employers

## Fairness

*In 2019, “Berkeley researchers found that both face-to-face and online lenders
rejected a total of 1.3 million creditworthy Black and Latino applicants between
2008 and 2015.” When the researchers “used the income and credit scores of the
rejected applications but deleted the race identifiers, the mortgage application was
accepted* ^[Khristopher J. Brooks, “Disparity in Home Lending Costs Minorities Millions, Researchers Find,” CBS News, November 15, 2019, https://oreil.ly/UiHUB.]


## Interpretability

- Interpretability is a requirement for many ML use cases in the industry

- It's important to understand why a decision is made so that we can trust a model and detect potential biases.

- It’s important for developers to be able to debug and improve a model.

# 2) Machine Learning Systems vs Traditional Software 

## ML Systems

- ML systems are part code, part data, and part artifacts created
from the two

- Usually applications developed with the most/best data win

- Instead of focusing on improving ML algorithms, most companies will focus on improving their data

- We need versioning for code and data

## Recap

-   
