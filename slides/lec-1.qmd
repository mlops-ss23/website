---
title: Overview of ML Systems
subtitle: Lecture 1
author: Jan Kirenz
format:
  revealjs:
    theme: default
    transition: fade
    slide-number: true
    chalkboard:
      buttons: false
    preview-links: auto
    logo: images/logo.png
    css: slides.scss
    footer: MLOps | Jan Kirenz
    incremental: true 
#jupyter: python3
---


## ML Systems Design

![ML System](images/lec-1/fig-1-1-mlsystem.png)


## When to use Machine Learning

Machine learning is an approach to (1) learn (2) complex patterns from (3) existing data and use these patterns to make (4) predictions on (5) unseen data.

## The system has the capacity to learn  

- Supervised learning



## There are patterns to learn, and they are complex  


![ML solutions learn patterns](images/lec-1/fig-1-2-patterns.png)


## Data is available, or it’s possible to collect data


## It's a predicitve problem

- What would the answer to this question be?

## Unseen data shares patterns with the training data

## Additional characteristics

- It's repetitive  

- The cost of wrong predictions is cheap  

- It's at scale  

- The patterns are constantly changing  

- It's not unethical

- It's cost effective (in the long run)


## Machine Learning Use Cases

- Recommender system   

- Machine translation 

- Computer vision

- Chat bots

## Machine Learning Use Cases


{{< video https://www.youtube.com/embed/DEjyUkbVVHA width="1920" height="1080" >}}



[150 Successful Machine Learning Models: 6 Lessons Learned at Booking.com](https://booking.ai/150-successful-machine-learning-models-6-lessons-learned-at-booking-com-681e09107bec)


## Machine Learning Use Cases

- Fraud detection  

- Price optimization

- Customer acquisition

- Churn prediction 

- Customer support

- Brand monitoring (sentiment analysis)


## State of AI

[State of AI in 2022 by McKinsey & Company](https://www.mckinsey.com/capabilities/quantumblack/our-insights/the-state-of-ai-in-2022-and-a-half-decade-in-review#review)


# Understanding Machine Learning Systems

## ML in Research vs in Production

|                        | Research                                                 | Production                                         |
| ---------------------- | -------------------------------------------------------- | -------------------------------------------------- |
| Requirements           | State-of-the-art model performance on benchmark datasets | Different stakeholders have different requirements |
| Computational priority | Fast training, high throughput                           | Fast inference, low latency                        |
| Data                   | Statica                                                  | Constantly shifting                                |
| Fairness               | Often not a focus                                        | Must be considered                                 |
| Interpretability       | Often not a focus                                        | Must be considered                                 |


## Different Stakeholders and requirements

- Consider a mobile app that recommends restaurants to users. 
- The app makes money by charging restaurants a 10% service fee on each order. 
- This means that expensive orders give the app more money than cheap orders.


## ML engineers

Want a model that recommends restaurants that users will most likely order
from, and they believe they can do so by using a more complex model with more
data.

## Sales team

Wants a model that recommends the more expensive restaurants since these
restaurants bring in more service fees.

## Product team

Notices that every increase in latency leads to a drop in orders through the
service, so they want a model that can return the recommended restaurants in
less than 100 milliseconds.


## ML platform team

As the traffic grows, this team has been woken up in the middle of the night
because of problems with scaling their existing system, so they want to hold off
on model updates to prioritize improving the ML platform.


## Manager

Wants to maximize the margin, and one way to achieve this might be to let go of
the ML team.

## Different Model Objectives

- Model A: Recommending the restaurants that users are most likely to click on

- Model B: Recommending the restaurants that will bring in the most money for the app

- Which model should be deployed to the users?

- Must-have vs nice-to-have requirements 

## Kaggle vs ML in Production


- Incentivizing the creation of more accurate models at the expense of other qualities
valued by practitioners such as compactness, fairness, and energy efficiency.

- Ensemble vs compact model

- Netflix price

## Computational priorities

- Research usually prioritizes fast training

- Production usually prioritizes fast inference

- Research prioritizes high throughput ^[how many
queries are processed within a specific period of time] 

- Production prioritizes low latency ^[the time it takes from receiving a query to returning the result]

## Latency

- It’s a common practice to use high percentiles to specify the performance require‐
ments for your system

- For example, a product manager might specify that the 90th percentile or 99.9th percentile latency of a system must be below a certain number

## Data in research versus data in production 


![](images/lec-1/fig-1-5-sleep.png)



- Source: Andrej Karpathy, “Building the Software 2.0 Stack,” Spark+AI Summit 2018, video, 17:54,
https://oreil.ly/Z21Oz.


## Fairness

- Your loan application might be rejected because the ML algorithm picks on your zip code, which embodies biases about one’s socioeconomic background. 
- Your resume might be ranked lower because the ranking system employers use picks on the spelling of your name. 
- Your mortgage might get a higher interest rate because it relies partially on credit scores, which favor the
rich and punish the poor. 
- Other examples of ML biases in the real world are in predictive policing algorithms, personality tests administered by potential employers, and college rankings.


## Fairness

- In 2019, “Berkeley researchers found that both face-to-face and online lenders
rejected a total of 1.3 million creditworthy Black and Latino applicants between
2008 and 2015.” When the researchers “used the income and credit scores of the
rejected applications but deleted the race identifiers, the mortgage application was
accepted.”

- Khristopher J. Brooks, “Disparity in Home Lending Costs Minorities Millions, Researchers Find,” CBS News,
November 15, 2019, https://oreil.ly/UiHUB.

## Interpretability

- Interpretability
isn’t just optional for most ML use cases in the industry, but a requirement.

- First, interpretability is important for users, both business leaders and end users, to
understand why a decision is made so that they can trust a model and detect potential
biases mentioned previously.

- Second, it’s important for developers to be able to debug and improve a model.